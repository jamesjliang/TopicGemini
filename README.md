# TopicGemini
Leveraging LLMs to improve existing Topic Modelling methods

## Project Background:
Topic Modelling is a common, yet deeply fascinating component of Natural Language Processing.
Usually, traditional approaches to this problem involve either:

    (1) Latent Dirichlet Allocation (LDA) 
    
    (2) Clustering and extracting centroid terms.

However, both these methods suffer from unsatisfactory topic granularity in the extracted terms,
and often, require a professional human curator to relabel the extracted 'topic' terms.

With the introduction of Large Language Models such as GPT-4 or Gemini, which are capable of incorporating semantic understanding
into natural language processing, TopicGemini explores the potential of how LLMs can be leveraged to 
improve existing processes in Topic Modelling, making them more effective for topic extraction.

## Inputs and Outputs
Input : Text Corpus                         
Output: Topic Hierarchy of Corpus - with RAG supplemented summarisations for finer granularity topics.

#### Quickstart
To generate the topic hierarchy and RAG supplemented summarisations, run main.py. 

Please note that this requires an active Google Gemini API key. To view the sample outputs, refer to the sample directory.

## Methodology
<img width="1082" alt="image" src="https://github.com/jamesliang728/TopicGemini/assets/161998923/cc151e69-f53c-4de5-a7d2-56a7853f17e2">

Traditional approaches to Topic Modelling via text embeddings and clustering often assume topic terms as the "centroid" of a cluster. The optimal number of clusters, k, is usually determined via running complex mathematical metrics that compare various values of k, to determine its best value.

The drawback of these methods, are that the centroids of clusters, whilst representative of topics, do not reflect a topic granularity themselves. Furthermore, the number of clusters k, is usually determined by a rather subjective parameter that is difficult to optimise for all scenarios.

The key contribution of TopicGemini involves the leverage of LLMs for topic refinement, after which the topic clusters have been created via kmeans.

During the LLM refinement process, I feed the LLM up to the top 1000 center terms of a cluster (determined via cosine similarity) to ensure that the keywords fed to the model is as semantically different from other clusters as possible. After the LLM is able to extract a suitable topic (by using its massive training data), I assign a topic to each cluster.

From this point, the LLM will combine semantically similar clusters (as determined by the topic assigned to each cluster). We will recursively run the algorithm on each cluster, until the desired topic granularity is reached.

Therefore, the TopicGemini focuses on 2 main things:
1. Topic Extraction (for appropriate topic granularity)
2. K-cluster determination (by combining semantically similar clusters).

## Retrieval Augmented Generation (RAG)
An implementation of Retrieval Augmented Generation (RAG) is provided if users are interested in extracting an even finer granularity summary of a specific topic that is being discussed. Image below from LangChain.
![image](https://github.com/jamesliang728/TopicGemini/assets/161998923/9c83ad7c-8a5e-4b24-87e0-16a012f11733)

In TopicGemini, a vector store is created by:

    1. Loading a Document object
    
    2. Chunking the document (if: for_document = False)
    
    3. Embedding via GoogleGenerativeAIEmbeddings, and using Chroma for VectorStore.

When running RAG in TopicGemini, you are able to get:

    (1) The summary response to the prompt. 
    
    (2) The news documents that were used to generate its response.

## Sample Results
A sample output of the Topic Hierarchy generated by TopicGemini, and the true labels (true_labels.txt) is featured in the samples directory.
With no other contextual information beyond the input corpus, TopicGemini semantically recovers majority of the high level topics such as sports, government, or arts.


##### References
References for images:

Corpus Iimages
https://botpenguin.com/glossary/corpus

Embedding image
https://www.linkedin.com/pulse/k-means-clustering-its-applications-ritvik-ranjan/

Kmeans image
https://towardsdatascience.com/creating-word-embeddings-coding-the-word2vec-algorithm-in-python-using-deep-learning-b337d0ba17a8

LLM image
https://techcommunity.microsoft.com/t5/educator-developer-blog/understanding-the-difference-in-using-different-large-language/ba-p/3919444

Langchain image
https://python.langchain.com/docs/modules/data_connection/vectorstores/

